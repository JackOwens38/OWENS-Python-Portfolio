{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The quick brown fox doesn't jump over the lazy dog. Natural Language Processing is fascinating!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', \"doesn't\", 'jump', 'over', 'the', 'lazy', 'dog.', 'Natural', 'Language', 'Processing', 'is', 'fascinating!']\n"
     ]
    }
   ],
   "source": [
    "# This uses only the python .split() method, which is good, but certainly not the best\n",
    "tokens_split = text.split()\n",
    "print(tokens_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'does', \"n't\", 'jump', 'over', 'the', 'lazy', 'dog', '.', 'Natural', 'Language', 'Processing', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "# This is how to use spaCy to tokenize, instead of using just the .split() method\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "tokens_spacy = [token.text for token in doc]\n",
    "print(tokens_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split(): ['The', 'quick', 'brown', 'fox', \"doesn't\", 'jump', 'over', 'the', 'lazy', 'dog.', 'Natural', 'Language', 'Processing', 'is', 'fascinating!']\n",
      "spaCy: ['The', 'quick', 'brown', 'fox', 'does', \"n't\", 'jump', 'over', 'the', 'lazy', 'dog', '.', 'Natural', 'Language', 'Processing', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "# Here is a side by side comparison of the two\n",
    "print(\"Split():\", tokens_split)\n",
    "print(\"spaCy:\", tokens_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The' (Definite=Def|PronType=Art) has a base form of 'the' and its syntactic head is 'fox'.\n",
      "'quick' (Degree=Pos) has a base form of 'quick' and its syntactic head is 'fox'.\n",
      "'brown' (Degree=Pos) has a base form of 'brown' and its syntactic head is 'fox'.\n",
      "'fox' (Number=Sing) has a base form of 'fox' and its syntactic head is 'jump'.\n",
      "'does' (Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin) has a base form of 'do' and its syntactic head is 'jump'.\n",
      "'n't' (Polarity=Neg) has a base form of 'not' and its syntactic head is 'jump'.\n",
      "'jump' (VerbForm=Inf) has a base form of 'jump' and its syntactic head is 'jump'.\n",
      "'over' () has a base form of 'over' and its syntactic head is 'jump'.\n",
      "'the' (Definite=Def|PronType=Art) has a base form of 'the' and its syntactic head is 'dog'.\n",
      "'lazy' (Degree=Pos) has a base form of 'lazy' and its syntactic head is 'dog'.\n",
      "'dog' (Number=Sing) has a base form of 'dog' and its syntactic head is 'over'.\n",
      "'.' (PunctType=Peri) has a base form of '.' and its syntactic head is 'jump'.\n",
      "'Natural' (Number=Sing) has a base form of 'Natural' and its syntactic head is 'Language'.\n",
      "'Language' (Number=Sing) has a base form of 'Language' and its syntactic head is 'Processing'.\n",
      "'Processing' (Number=Sing) has a base form of 'processing' and its syntactic head is 'is'.\n",
      "'is' (Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin) has a base form of 'be' and its syntactic head is 'is'.\n",
      "'fascinating' (Degree=Pos) has a base form of 'fascinating' and its syntactic head is 'is'.\n",
      "'!' (PunctType=Peri) has a base form of '!' and its syntactic head is 'is'.\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"'{token.text}' ({token.morph}) has a base form of '{token.lemma_}' and its syntactic head is '{token.head}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. spaCy often processes the tokens by splitting each word into its own instance. However, sometimes it separates a word into multiple instances, such as contractions (like \"doesn't in this example). It also takes punctuation marks into account. When this is done, you can then use the functions above (and many others) to gather information on each word within spaCy's databse, as well as how the words relate to each other.\n",
    "2. Punctuation marks are treated very similarly to most words, and each have their own instance. They also have relationships with theh words around them, and each mark has distinct data within spaCy's database.\n",
    "3. As mentioned before, contractions are typically split up into multiple instances. When this happens, each word can be analyzed indpendently on a more careful level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The | DET | DT\n",
      "quick | ADJ | JJ\n",
      "brown | ADJ | JJ\n",
      "fox | NOUN | NN\n",
      "does | AUX | VBZ\n",
      "n't | PART | RB\n",
      "jump | VERB | VB\n",
      "over | ADP | IN\n",
      "the | DET | DT\n",
      "lazy | ADJ | JJ\n",
      "dog | NOUN | NN\n",
      ". | PUNCT | .\n",
      "Natural | PROPN | NNP\n",
      "Language | PROPN | NNP\n",
      "Processing | NOUN | NN\n",
      "is | AUX | VBZ\n",
      "fascinating | ADJ | JJ\n",
      "! | PUNCT | .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text} | {token.pos_} | {token.tag_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".pos_ and .tag_ give even more information on each token, with .tag_ giving a slightly more in depth view.\n",
    "1. As you can see in the output, \"quick\" is an adjective, \"jump\" is the base form of a verb, and \"is\" is a 3rd person singular present tense verb.\n",
    "2. Gathering parts of speech through spaCy is a great tool for grammar and translating, because all of these words often have varying forms depending on context. Knowing the part of speech gives a lot of context, making the outputs more accurate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barack', 'Obama', 'was', 'the', '44th', 'President', 'of', 'the', 'United', 'States', '.', 'He', 'was', 'born', 'in', 'Hawaii', '.']\n",
      "Barack Obama: PERSON (People, including fictional)\n",
      "44th: ORDINAL (\"first\", \"second\", etc.)\n",
      "the United States: GPE (Countries, cities, states)\n",
      "Hawaii: GPE (Countries, cities, states)\n"
     ]
    }
   ],
   "source": [
    "text = \"Barack Obama was the 44th President of the United States. He was born in Hawaii.\"\n",
    "doc = nlp(text)\n",
    "tokens_spacy = [token.text for token in doc]\n",
    "print(tokens_spacy)\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text}: {ent.label_} ({spacy.explain(ent.label_)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The entities recognized by spaCy are Barack Obama, 44th, United States, and Hawaii\n",
    "2. Barack Obama is recognized as a Person, while Hawaii is a state under the category GPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'They | base form: 'they' | PoS: PRON\n",
      "'lost | base form: 'lose' | PoS: VERB\n",
      "'they | base form: 'they' | PoS: PRON\n",
      "''re | base form: 'be' | PoS: AUX\n",
      "'luggage | base form: 'luggage' | PoS: NOUN\n",
      "'in | base form: 'in' | PoS: ADP\n",
      "'the | base form: 'the' | PoS: DET\n",
      "'airport | base form: 'airport' | PoS: NOUN\n",
      "'in | base form: 'in' | PoS: ADP\n",
      "'Atlanta | base form: 'Atlanta' | PoS: PROPN\n",
      "', | base form: ',' | PoS: PUNCT\n",
      "'Georgia | base form: 'Georgia' | PoS: PROPN\n",
      "', | base form: ',' | PoS: PUNCT\n",
      "'before | base form: 'before' | PoS: ADP\n",
      "'landing | base form: 'land' | PoS: VERB\n",
      "'in | base form: 'in' | PoS: ADP\n",
      "'Russia | base form: 'Russia' | PoS: PROPN\n",
      "'and | base form: 'and' | PoS: CCONJ\n",
      "'crossing | base form: 'cross' | PoS: VERB\n",
      "'the | base form: 'the' | PoS: DET\n",
      "'border | base form: 'border' | PoS: NOUN\n",
      "'into | base form: 'into' | PoS: ADP\n",
      "'Georgia | base form: 'Georgia' | PoS: PROPN\n",
      "'with | base form: 'with' | PoS: ADP\n",
      "'are | base form: 'be' | PoS: AUX\n",
      "'friends | base form: 'friend' | PoS: NOUN\n",
      "'. | base form: '.' | PoS: PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = \"They lost they're luggage in the airport in Atlanta, Georgia, before landing in Russia and crossing the border into Georgia with are friends.\"\n",
    "doc = nlp(text)\n",
    "tokens_spacy = [token.text for token in doc]\n",
    "for token in doc:\n",
    "    print(f\"'{token.text} | base form: '{token.lemma_}' | PoS: {token.pos_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After modifying words a bit, I realized spaCy struggled with texts that were not exactly correct. I included \"they're\" when it should have been \"their\", and spaCy did not pick up on the difference. The same goes for \"are\" instead of \"our\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlanta: GPE (Countries, cities, states)\n",
      "Georgia: GPE (Countries, cities, states)\n",
      "Russia: GPE (Countries, cities, states)\n",
      "Georgia: GPE (Countries, cities, states)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">They lost they're luggage in the airport in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Atlanta\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Georgia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", before landing in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Russia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and crossing the border into \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Georgia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " with are friends.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text}: {ent.label_} ({spacy.explain(ent.label_)})\")\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While I tried to confuse spaCy by including both Goergia the state and Georgia the country in my sentence, it just includes them both in a more broad category. This could also be an issue though, as many cities, states, and countries share the same name. Not including differentiation between them could cause issues if specificity is needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
