{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJBs_flRovLc"
   },
   "source": [
    "## Using spaCy for NLP Tasks\n",
    "\n",
    "This notebook demonstrates how to install and use spaCy to perform various Natural Language Processing (NLP) tasks.\n",
    "\n",
    "In today’s lesson we will:\n",
    "\n",
    "- Install spaCy and download its statistical models.\n",
    "- Read and process a text file.\n",
    "- Perform Named Entity Recognition (NER) to extract entities from text.\n",
    "- Visualize entity counts.\n",
    "- Explore and customize the spaCy pipeline (including using the EntityRuler)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ans8WJUUj8qI"
   },
   "source": [
    "### 1. Installation\n",
    "To get started, you must install spaCy and the English language model.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Use `pip install spacy` to install the core library.\n",
    "2. Download the English model (`en_core_web_sm`) which includes the statistical model for English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8aj7OGAkCcx"
   },
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCjfqkKMkrY-"
   },
   "source": [
    "### 2. Loading the spaCy Model\n",
    "\n",
    "Once downloaded, those models can be opened via **spacy.load('model_name')** in python. Therefore, you can verify if the models were downloaded successfully by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJr_9dXGpJ05"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFPkM3QLc9qf"
   },
   "source": [
    "### 3. Reading a Text File\n",
    "Here, we read in a text file that contains a chapter from *The Fellowship Of The Ring*. Make sure the file is in your working directory (or provide the full path).\n",
    "\n",
    "**Key Steps:**\n",
    "- Open the file using Python’s built-in `open()` function.\n",
    "- Read the content into a variable.\n",
    "- Adjust `nlp.max_length` to avoid errors when processing long texts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9MWj4EuNvNK"
   },
   "outputs": [],
   "source": [
    "# Define the file path (adjust this path if your file is stored elsewhere)\n",
    "lotr_script = '/content/The Fellowship Of The Ring_Ch1 (1).txt'\n",
    "\n",
    "# Read the file content\n",
    "with open(lotr_script, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Adjust the maximum allowed length for the NLP model to process the full text\n",
    "nlp.max_length = len(text)\n",
    "\n",
    "# Process the text with the spaCy model\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gE-Ez1qtyIA"
   },
   "outputs": [],
   "source": [
    "# Increase the max_length to handle the large text, avoids an error\n",
    "nlp.max_length = len(text) # Sets the maximum length to the length of the text\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exe29dKGjGir"
   },
   "source": [
    "### 4. Named Entity Recognition (NER)\n",
    "\n",
    "Named Entity Recognition identifies and classifies entities (like names of people, places, or organizations) in text.\n",
    "**What we'll do:**\n",
    "- Extract entities from the processed document.\n",
    "- Create a Pandas DataFrame that shows the entity text and its corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5etHS43jL0g"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list to collect entity data\n",
    "entities_data = []\n",
    "\n",
    "# Extract each entity and its label from the document\n",
    "\n",
    "\n",
    "# Convert the list into a DataFrame for easier viewing\n",
    "\n",
    "# Display the entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oH8kcexJU5g8"
   },
   "source": [
    "### 5. Analyzing Entity Data\n",
    "Let's examine:\n",
    "- **Text and Label Frequency:**  \n",
    "Display the most common entity texts and their labels.\n",
    "- **Entity Details:**  \n",
    "Use spaCy's built-in explanation function to understand what a specific label (e.g., \"FAC\") means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0R0AmwYV_qj"
   },
   "outputs": [],
   "source": [
    "# Display the top 15 most common texts and labels\n",
    "\n",
    "# Explain a specific entity label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drU2gC30_g8q"
   },
   "outputs": [],
   "source": [
    "# Display combinations of text and label counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ws6P7bHT_i0b"
   },
   "outputs": [],
   "source": [
    "# List unique labels in the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHksIATSjXEF"
   },
   "source": [
    "###  6. Exploring the NLP Pipeline\n",
    "[NLP Pipeline Documentation](https://spacy.io/usage/processing-pipelines#processing)\n",
    "\n",
    "You can inspect the components of the NLP pipeline `nlp.pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9iiD5GBdTNu"
   },
   "outputs": [],
   "source": [
    "# Spacy's language model pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gw9yYQJlWbpu"
   },
   "source": [
    "### 7. Visualizing Entities with DisplaCy\n",
    "DisplaCy is spaCy’s visualization tool for rendering entities and dependencies in Jupyter notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DafBeVakWgQl"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "# Render entities in the processed document using DisplaCy\n",
    "displacy.render(doc, style = \"ent\", jupyter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiKdRq51h6BD"
   },
   "source": [
    "### 8. Identifying Issues in the Named Entity Recognizer\n",
    "\n",
    "Use the [Lord of the Rings Wiki](https://lotr.fandom.com/wiki/Main_Page) if you need help\n",
    "\n",
    "Example Issues: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEXt_fWGgvw-"
   },
   "source": [
    "### 9. Creating Custom Entity Recognizers with the EntityRuler\n",
    "\n",
    "Custom patterns can be added to the pipeline using spaCy's `EntityRuler`. This allows us to capture entities that might be missed by the statistical model.\n",
    "\n",
    "**Steps:**\n",
    "- Define custom entity patterns (as a list of dictionaries).\n",
    "- Check if the \"ner\" component exists and add the EntityRuler accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLIskVAMQ29B"
   },
   "source": [
    "[EntityRuler Documentation](https://spacy.io/api/entityruler#add_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "giLScuq6KIel"
   },
   "outputs": [],
   "source": [
    "# Define custom entity patterns for names, locations, and other entities\n",
    "entity_patterns = [\n",
    "\n",
    "\n",
    " ]\n",
    "\n",
    "#Add EntityRuler to the pipeline\n",
    "#ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "#ruler.add_patterns(entity_patterns)\n",
    "\n",
    "#Access the existing entity_ruler\n",
    "#ruler = nlp.get_pipe(\"entity_ruler\")\n",
    "\n",
    "#Add your custom patterns\n",
    "#ruler.add_patterns(entity_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZMQGkZXFv2q"
   },
   "outputs": [],
   "source": [
    "# Check if the \"ner\" pipe exists. If it does, add the EntityRuler before it.\n",
    "\n",
    "    # If entity_ruler already exists, simply add patterns to it.\n",
    "\n",
    "    # If the NER component does not exist, add both the EntityRuler and the NER component.\n",
    "\n",
    "# Check updated pipeline labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Opw-lzPZWsU"
   },
   "source": [
    "### 10. Testing the Custom Entity Ruler\n",
    "Run a sample sentence through the updated pipeline to check if your custom patterns are recognized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2O5Ge2r3LP9u"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc_2 = nlp(\"Gandalf went to Bilbo's house for his birthday because he was my precious which is the Ring.\")\n",
    "displacy.render(doc_2, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPOU5FyuQ-Md"
   },
   "source": [
    "### 11. Re-Processing the Full Text\n",
    "Now that we have updated the pipeline with our custom patterns, re-run the full text to see how the recognizer performs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62RVMVg6M3DW"
   },
   "outputs": [],
   "source": [
    "# Re-process the text with the updated pipeline\n",
    "nlp.max_length = len(text)\n",
    "doc = nlp(text)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeVGXJYmYySk"
   },
   "source": [
    "### 12. Re-Analyzing Entity Data\n",
    "Let's again create a DataFrame from the updated document to see if our custom recognitions improved entity extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jh-a6rd-mDpO"
   },
   "outputs": [],
   "source": [
    "# Collect entities from the updated document\n",
    "entities_data = []\n",
    "for ent in doc.ents:\n",
    "    entities_data.append({\n",
    "        'text': ent.text,\n",
    "        'label': ent.label_\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "ent_df = pd.DataFrame(entities_data)\n",
    "ent_df\n",
    "\n",
    "# %%\n",
    "# Show value counts for text and label combinations after the update\n",
    "print(\"Updated Text and Label Combinations (Top 20):\")\n",
    "print(ent_df[['text', 'label']].value_counts()[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVbasK5wXAX_"
   },
   "source": [
    "### 13. Visualizing Entity Data\n",
    "Finally, we create a bar plot to visualize the top 10 most common text and label combinations.\n",
    "**Steps:**\n",
    "- Use Pandas to compute counts.\n",
    "- Plot the counts using Seaborn and Matplotlib.\n",
    "\n",
    "**Tree Map**\n",
    "- The `color` parameter is set to `label` so that each entity label gets a distinct color.\n",
    "\n",
    "- The `path` parameter defines a hierarchy where entities are grouped by their `label` first, then by `text`.\n",
    "\n",
    "- This interactive treemap allows students to easily see how different entity labels contribute to the overall counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IZa1cJHlamc"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Prepare the data for visualization: top 10 entity combinations\n",
    "top_10_ents = ent_df[['text', 'label']].value_counts().head(10).reset_index(name='counts')\n",
    "\n",
    "# Create a treemap using a hierarchical structure (first by label, then by text)\n",
    "fig = px.treemap(top_10_ents,\n",
    "                path=['label', 'text'],\n",
    "                values='counts',\n",
    "                title='Top 10 Text and Label Combinations (Treemap)',\n",
    "                color='label')\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
